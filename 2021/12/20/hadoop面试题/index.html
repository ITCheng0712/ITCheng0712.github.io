<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>hadoop面试题 | CloudHao</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="1.什么是Hadoop？HDFS+Yarn+MapReduce，对大量数据进行分布式处理的软件框架。以一种可靠、高效、可伸缩的方式进行数据处理。广义上指一个生态圈，泛指大数据技术相关的开源产品。 2.Hadoop和Spark的差异   - Hadoop Spark    类型 基础平台，包含存储、计算、调度 分布式计算框架   场景 大规模数据集上的批处理 迭代计算、交互式计算、流计算   价格">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop面试题">
<meta property="og:url" content="http://example.com/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/index.html">
<meta property="og:site_name" content="CloudHao">
<meta property="og:description" content="1.什么是Hadoop？HDFS+Yarn+MapReduce，对大量数据进行分布式处理的软件框架。以一种可靠、高效、可伸缩的方式进行数据处理。广义上指一个生态圈，泛指大数据技术相关的开源产品。 2.Hadoop和Spark的差异   - Hadoop Spark    类型 基础平台，包含存储、计算、调度 分布式计算框架   场景 大规模数据集上的批处理 迭代计算、交互式计算、流计算   价格">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/HDFS%E8%AF%BB%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://example.com/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/HDFS%E5%86%99%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://example.com/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/MapReduce%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://example.com/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/%E5%8E%8B%E7%BC%A9.png">
<meta property="og:image" content="http://example.com/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/Yarn%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B(%E8%AF%A6%E7%BB%86).png">
<meta property="og:image" content="http://example.com/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/Yarn%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B(%E7%AE%80%E7%95%A5).png">
<meta property="article:published_time" content="2021-12-20T06:33:33.000Z">
<meta property="article:modified_time" content="2021-12-23T02:02:50.021Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="面试">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/HDFS%E8%AF%BB%E6%B5%81%E7%A8%8B.png">
  
    <link rel="alternate" href="/atom.xml" title="CloudHao" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">CloudHao</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-hadoop面试题" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/" class="article-date">
  <time class="dt-published" datetime="2021-12-20T06:33:33.000Z" itemprop="datePublished">2021-12-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      hadoop面试题
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-什么是Hadoop？"><a href="#1-什么是Hadoop？" class="headerlink" title="1.什么是Hadoop？"></a>1.什么是Hadoop？</h2><p>HDFS+Yarn+MapReduce，对大量数据进行分布式处理的软件框架。以一种可靠、高效、可伸缩的方式进行数据处理。<br>广义上指一个生态圈，泛指大数据技术相关的开源产品。</p>
<h2 id="2-Hadoop和Spark的差异"><a href="#2-Hadoop和Spark的差异" class="headerlink" title="2.Hadoop和Spark的差异"></a>2.Hadoop和Spark的差异</h2><table>
<thead>
<tr>
<th>-</th>
<th align="left">Hadoop</th>
<th align="left">Spark</th>
</tr>
</thead>
<tbody><tr>
<td>类型</td>
<td align="left">基础平台，包含存储、计算、调度</td>
<td align="left">分布式计算框架</td>
</tr>
<tr>
<td>场景</td>
<td align="left">大规模数据集上的批处理</td>
<td align="left">迭代计算、交互式计算、流计算</td>
</tr>
<tr>
<td>价格</td>
<td align="left">对机器要求低</td>
<td align="left">对内存有要求</td>
</tr>
<tr>
<td>编程范式</td>
<td align="left">MapReduce，API 较为底层，算法适应性差</td>
<td align="left">RDD组成DAG有向无环图，API较为顶层，方便使用</td>
</tr>
<tr>
<td>数据存储结构</td>
<td align="left">MapReduce计算的中间结果存储在HDFS磁盘上，延迟高</td>
<td align="left">RDD结果存储在内存中，延迟低</td>
</tr>
<tr>
<td>运行方式</td>
<td align="left">Task以进程方式维护，任务启动慢</td>
<td align="left">Task以线程方式维护，任务启动快</td>
</tr>
</tbody></table>
<h2 id="3-Hadoop常见的版本有哪些？"><a href="#3-Hadoop常见的版本有哪些？" class="headerlink" title="3.Hadoop常见的版本有哪些？"></a>3.Hadoop常见的版本有哪些？</h2><p>CDH：有可用的开源免费包，但是本身不在开源、免费，易维护但扩展性差。<br>Apache：完全开源、免费，不易维护。<br>Hortonworks：有可用的HDP包，但是本身不在免费，易维护但扩展性差。</p>
<h2 id="4-简单介绍Hadoop1-0，2-0，3-0的区别"><a href="#4-简单介绍Hadoop1-0，2-0，3-0的区别" class="headerlink" title="4.简单介绍Hadoop1.0，2.0，3.0的区别"></a>4.简单介绍Hadoop1.0，2.0，3.0的区别</h2><h5 id="Hadoop1-0："><a href="#Hadoop1-0：" class="headerlink" title="Hadoop1.0："></a>Hadoop1.0：</h5><ul>
<li>由HDFS和MapReduce构成，HDFS由一个NameNode和多个DataNode组成，MapReduce由一个JobTracker和多个TaskTracker组成。Hadoop1.0易发生单点故障，拓展性差，性能低。</li>
</ul>
<h5 id="Hadoop2-0，为克服1-0中不足，提出了："><a href="#Hadoop2-0，为克服1-0中不足，提出了：" class="headerlink" title="Hadoop2.0，为克服1.0中不足，提出了："></a>Hadoop2.0，为克服1.0中不足，提出了：</h5><ul>
<li>Yarn，彻底代替了1.0中的JobTracker，在MRv1 中的 JobTracker 资源管理和作业跟踪的功能被抽象为 ResourceManager 和 AppMaster 两个组件。Yarn 还支持多种应用程序和框架，提供统一的资源调度和管理功能。</li>
<li>NameNode故障得以解决，在Hadoop2.2.0之后提供了主备NameNode方案，并支持 NFS，QJM 和 Zookeeper 三种可选的共享存储系统。</li>
<li>HDFS 快照，指 HDFS（或子系统）在某一时刻的只读镜像。(实战操作：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/JackQ/p/4586663.html">https://www.cnblogs.com/JackQ/p/4586663.html</a>)</li>
<li>支持Windows 操作系统。</li>
<li>Append，新版本的 Hadoop 引入了对文件的追加操作。</li>
</ul>
<h5 id="相比于Hadoop2-0，Hadoop3-0-是直接基于-JDK1-8-发布的一个新版本，同时，Hadoop3-0引入了一些重要的功能和特性："><a href="#相比于Hadoop2-0，Hadoop3-0-是直接基于-JDK1-8-发布的一个新版本，同时，Hadoop3-0引入了一些重要的功能和特性：" class="headerlink" title="相比于Hadoop2.0，Hadoop3.0 是直接基于 JDK1.8 发布的一个新版本，同时，Hadoop3.0引入了一些重要的功能和特性："></a>相比于Hadoop2.0，Hadoop3.0 是直接基于 JDK1.8 发布的一个新版本，同时，Hadoop3.0引入了一些重要的功能和特性：</h5><ul>
<li>HDFS可擦除编码：这项技术使HDFS在不降低可靠性的前提下节省了很大一部分存储空间</li>
<li>多NameNode支持：在Hadoop3.0中，新增了对多NameNode的支持。当然，处于Active状态的NameNode实例必须只有一个。也就是说，从Hadoop3.0开始，在同一个集群中，支持一个 ActiveNameNode 和 多个 StandbyNameNode 的部署方式。</li>
<li>MR Native Task优化</li>
<li>Yarn基于cgroup 的内存和磁盘 I/O 隔离</li>
<li>Yarn container resizing</li>
</ul>
<h2 id="5-Hadoop常用的端口号"><a href="#5-Hadoop常用的端口号" class="headerlink" title="5.Hadoop常用的端口号"></a>5.Hadoop常用的端口号</h2><ul>
<li>NameNode(dfs.namenode.http-address):50070,http服务的端口</li>
<li>NameNode(fs.defaultFS):8020,接收Client连接的RPC端口，用于获取文件系统metadata信息</li>
<li>Yarn webUI:8088</li>
<li>DataNode(dfs.datanode.address datanode):50010,服务端口，用于数据传输</li>
<li>DataNode(dfs.datanode.http.address):50075,http服务的端口</li>
<li>ZKFC(dfs.ha.zkfc.port):8019,ZooKeeper FailoverController，用于NN HA</li>
</ul>
<h2 id="6-简单介绍一下搭建Hadoop集群的流程"><a href="#6-简单介绍一下搭建Hadoop集群的流程" class="headerlink" title="6.简单介绍一下搭建Hadoop集群的流程"></a>6.简单介绍一下搭建Hadoop集群的流程</h2><p>linux基础准备：</p>
<ul>
<li>1.主机名修改，hosts配置。</li>
<li>2.免密配置</li>
<li>3.关闭防火墙</li>
<li>4.关闭selinux</li>
<li>5.JDK安装<br>搭建工作：</li>
<li>1.上传包</li>
<li>2.配置hadoop配置文件，包括hdfs-site.xml，yarn-site.xml等。</li>
<li>3.格式化NameNode。</li>
<li>4.启动。</li>
</ul>
<h2 id="7-介绍一下HDFS读写流程"><a href="#7-介绍一下HDFS读写流程" class="headerlink" title="7.介绍一下HDFS读写流程"></a>7.介绍一下HDFS读写流程</h2><h3 id="HDFS读流程："><a href="#HDFS读流程：" class="headerlink" title="HDFS读流程："></a>HDFS读流程：</h3><img src="/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/HDFS%E8%AF%BB%E6%B5%81%E7%A8%8B.png" class="" title="读流程图">

<h3 id="HDFS写流程："><a href="#HDFS写流程：" class="headerlink" title="HDFS写流程："></a>HDFS写流程：</h3><img src="/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/HDFS%E5%86%99%E6%B5%81%E7%A8%8B.png" class="" title="写流程图">


<h2 id="8-介绍一下MapReduce的Shuffle过程，并给出Hadoop优化的方案"><a href="#8-介绍一下MapReduce的Shuffle过程，并给出Hadoop优化的方案" class="headerlink" title="8.介绍一下MapReduce的Shuffle过程，并给出Hadoop优化的方案"></a>8.介绍一下MapReduce的Shuffle过程，并给出Hadoop优化的方案</h2><img src="/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/MapReduce%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B.png" class="" title="MapReduce计算流程图">

<h5 id="shuffle："><a href="#shuffle：" class="headerlink" title="shuffle："></a>shuffle：</h5><ul>
<li>Map方法之后Reduce方法之前这段处理过程叫「Shuffle」</li>
<li>Map方法之后，数据首先进入到分区方法，把数据标记好分区，然后把数据发送到环形缓冲区；环形缓冲区默认大小100m，环形缓冲区达到80%时，进行溢写；溢写前对数据进行排序，排序按照对key的索引进行字典顺序排序，排序的手段「快排」；溢写产生大量溢写文件，需要对溢写文件进行「归并排序」；对溢写的文件也可以进行Combiner操作，前提是汇总操作，求平均值不行。最后将文件按照分区存储到磁盘，等待Reduce端拉取。</li>
<li>每个Reduce拉取Map端对应分区的数据。拉取数据后先存储到内存中，内存不够了，再存储到磁盘。拉取完所有数据后，采用归并排序将内存和磁盘中的数据都进行排序。在进入Reduce方法前，可以对数据进行分组操作。</li>
</ul>
<h3 id="hadoop优化方案："><a href="#hadoop优化方案：" class="headerlink" title="hadoop优化方案："></a>hadoop优化方案：</h3><h5 id="1-HDFS小文件影响"><a href="#1-HDFS小文件影响" class="headerlink" title="1.HDFS小文件影响"></a>1.HDFS小文件影响</h5><ul>
<li>影响NameNode的寿命，因为文件元数据存储在NameNode的内存中</li>
<li>影响计算引擎的任务数量，比如每个小的文件都会生成一个Map任务</li>
</ul>
<h5 id="2-数据输入小文件处理"><a href="#2-数据输入小文件处理" class="headerlink" title="2.数据输入小文件处理"></a>2.数据输入小文件处理</h5><ul>
<li>合并小文件：对小文件进行归档（Har）、自定义Inputformat将小文件存储成SequenceFile文件。</li>
<li>采用ConbinFileInputFormat来作为输入，解决输入端大量小文件场景</li>
<li>对于大量小文件Job，可以开启JVM重用</li>
</ul>
<h5 id="3-Map阶段"><a href="#3-Map阶段" class="headerlink" title="3.Map阶段"></a>3.Map阶段</h5><ul>
<li>增大环形缓冲区大小。由100m扩大到200m</li>
<li>增大环形缓冲区溢写的比例。由80%扩大到90%</li>
<li>减少对溢写文件的merge次数。（10个文件，一次20个merge）</li>
<li>不影响实际业务的前提下，采用Combiner提前合并，减少 I/O</li>
</ul>
<h5 id="4-Reduce阶段"><a href="#4-Reduce阶段" class="headerlink" title="4.Reduce阶段"></a>4.Reduce阶段</h5><ul>
<li>合理设置Map和Reduce数：两个都不能设置太少，也不能设置太多。太少，会导致Task等待，延长处理时间；太多，会导致 Map、Reduce任务间竞争资源，造成处理超时等错误。</li>
<li>设置Map、Reduce共存：调整 slowstart.completedmaps 参数，使Map运行到一定程度后，Reduce也开始运行，减少Reduce的等待时间</li>
<li>规避使用Reduce，因为Reduce在用于连接数据集的时候将会产生大量的网络消耗。</li>
<li>增加每个Reduce去Map中拿数据的并行数</li>
<li>集群性能可以的前提下，增大Reduce端存储数据内存的大小</li>
</ul>
<h5 id="5-IO传输"><a href="#5-IO传输" class="headerlink" title="5.IO传输"></a>5.IO传输</h5><ul>
<li>采用数据压缩的方式，减少网络IO的的时间</li>
<li>使用SequenceFile二进制文件</li>
</ul>
<h5 id="6-参数调优"><a href="#6-参数调优" class="headerlink" title="6.参数调优"></a>6.参数调优</h5><ul>
<li>MapTask默认内存大小为1G，可以增加MapTask内存大小为4</li>
<li>ReduceTask默认内存大小为1G，可以增加ReduceTask内存大小为4-5g</li>
<li>可以增加MapTask的cpu核数，增加ReduceTask的CPU核数</li>
<li>增加每个Container的CPU核数和内存大小</li>
<li>调整每个Map Task和Reduce Task最大重试次数</li>
</ul>
<h5 id="7-压缩"><a href="#7-压缩" class="headerlink" title="7.压缩"></a>7.压缩</h5><img src="/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/%E5%8E%8B%E7%BC%A9.png" class="">
<p>如果面试过程问起，我们一般回答压缩方式为Snappy，特点速度快，缺点无法切分（可以回答在链式MR中，Reduce端输出使用bzip2压缩，以便后续的map任务对数据进行split）</p>
<h2 id="9-介绍一下-Yarn-的-Job-提交流程"><a href="#9-介绍一下-Yarn-的-Job-提交流程" class="headerlink" title="9.介绍一下 Yarn 的 Job 提交流程"></a>9.介绍一下 Yarn 的 Job 提交流程</h2><h5 id="详细流程："><a href="#详细流程：" class="headerlink" title="详细流程："></a>详细流程：</h5><img src="/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/Yarn%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B(%E8%AF%A6%E7%BB%86).png" class="">

<h5 id="简略流程："><a href="#简略流程：" class="headerlink" title="简略流程："></a>简略流程：</h5><img src="/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/Yarn%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B(%E7%AE%80%E7%95%A5).png" class="">

<ul>
<li>1.client向RM提交应用程序，其中包括启动该应用的ApplicationMaster的必须信息，例如ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等</li>
<li>2.ResourceManager启动一个container用于运行ApplicationMaster</li>
<li>3.启动中的ApplicationMaster向ResourceManager注册自己，启动成功后与RM保持心跳</li>
<li>4.ApplicationMaster向ResourceManager发送请求,申请相应数目的container</li>
<li>5.申请成功的container，由ApplicationMaster进行初始化。container的启动信息初始化后，AM与对应的NodeManager通信，要求NM启动container</li>
<li>6.NM启动container</li>
<li>7.container运行期间，ApplicationMaster对container进行监控。container通过RPC协议向对应的AM汇报自己的进度和状态等信息</li>
<li>8.应用运行结束后，ApplicationMaster向ResourceManager注销自己，并允许属于它的container被收回</li>
</ul>
<h2 id="10-介绍下Yarn默认的调度器，调度器分类，以及它们之间的区别"><a href="#10-介绍下Yarn默认的调度器，调度器分类，以及它们之间的区别" class="headerlink" title="10.介绍下Yarn默认的调度器，调度器分类，以及它们之间的区别"></a>10.介绍下Yarn默认的调度器，调度器分类，以及它们之间的区别</h2><h5 id="Hadoop调度器主要分为三类："><a href="#Hadoop调度器主要分为三类：" class="headerlink" title="Hadoop调度器主要分为三类："></a>Hadoop调度器主要分为三类：</h5><ul>
<li>1.FIFO Scheduler：先进先出调度器：优先提交的，优先执行，后面提交的等待【生产环境不会使用】</li>
<li>2.Capacity Scheduler：容量调度器：允许看创建多个任务对列，多个任务对列可以同时执行。但是一个队列内部还是先进先出。【Hadoop2.7.2默认的调度器】</li>
<li>Fair Scheduler：公平调度器：第一个程序在启动时可以占用其他队列的资源（100%占用），当其他队列有任务提交时，占用资源的队列需要将资源还给该任务。还资源的时候，效率比较慢。【CDH版本的yarn调度器默认】</li>
</ul>
<h2 id="11-了解过哪些Hadoop的参数优化"><a href="#11-了解过哪些Hadoop的参数优化" class="headerlink" title="11.了解过哪些Hadoop的参数优化"></a>11.了解过哪些Hadoop的参数优化</h2><ul>
<li>在hdfs-site.xml文件中配置多目录，最好提前配置好，否则更改目录需要重新启动集群</li>
<li>NameNode有一个工作线程池，用来处理不同DataNode的并发心跳以及客户端并发的元数据操作 (dfs.namenode.handler.count=20 * log2(Cluster Size))</li>
<li>编辑日志存储路径dfs.namenode.edits.dir设置与镜像文件存储路径dfs.namenode.name.dir尽量分开，达到最低写入延迟</li>
<li>服务器节点上YARN可使用的物理内存总量，默认是8192（MB），注意，如果你的节点内存资源不够8GB，则需要调减小这个值，而YARN不会智能的探测节点的物理内存总量</li>
<li>单个任务可申请的最多物理内存量，默认是8192（MB）</li>
</ul>
<h2 id="12-了解过Hadoop的基准测试吗"><a href="#12-了解过Hadoop的基准测试吗" class="headerlink" title="12.了解过Hadoop的基准测试吗?"></a>12.了解过Hadoop的基准测试吗?</h2><p>搭建完Hadoop集群后需要对HDFS读写性能和MR计算能力测试。测试jar包在hadoop的share文件夹下。</p>
<h2 id="13-你是怎么处理Hadoop宕机的问题的"><a href="#13-你是怎么处理Hadoop宕机的问题的" class="headerlink" title="13.你是怎么处理Hadoop宕机的问题的?"></a>13.你是怎么处理Hadoop宕机的问题的?</h2><ul>
<li>如果MR造成系统宕机。此时要控制Yarn同时运行的任务数，和每个任务申请的最大内存。调整参数：yarn.scheduler.maximum-allocation-mb（单个任务可申请的最多物理内存量，默认是8192MB）。</li>
<li>如果写入文件过量造成NameNode宕机。那么调高Kafka的存储大小，控制从Kafka到HDFS的写入速度。高峰期的时候用Kafka进行缓存，高峰期过去数据同步会自动跟上。</li>
</ul>
<h2 id="14-你是如何解决Hadoop数据倾斜的问题的，能举个例子吗"><a href="#14-你是如何解决Hadoop数据倾斜的问题的，能举个例子吗" class="headerlink" title="14.你是如何解决Hadoop数据倾斜的问题的，能举个例子吗?"></a>14.你是如何解决Hadoop数据倾斜的问题的，能举个例子吗?</h2><h5 id="1）提前在map进行combine，减少传输的数据量"><a href="#1）提前在map进行combine，减少传输的数据量" class="headerlink" title="1）提前在map进行combine，减少传输的数据量"></a>1）提前在map进行combine，减少传输的数据量</h5><p>在Mapper加上combiner相当于提前进行reduce，即把一个Mapper中的相同key进行了聚合，减少shuffle过程中传输的数据量，以及Reducer端的计算量。<br>如果导致数据倾斜的key 大量分布在不同的mapper的时候，这种方法就不是很有效了。</p>
<h5 id="2）数据倾斜的key-大量分布在不同的mapper"><a href="#2）数据倾斜的key-大量分布在不同的mapper" class="headerlink" title="2）数据倾斜的key 大量分布在不同的mapper"></a>2）数据倾斜的key 大量分布在不同的mapper</h5><ul>
<li><p>第一次在map阶段对那些导致了数据倾斜的key 加上1到n的随机前缀，这样本来相同的key 也会被分到多个Reducer 中进行局部聚合，数量就会大大降低。<br>第二次mapreduce，去掉key的随机前缀，进行全局聚合。<br>「思想」：二次mr，第一次将key随机散列到不同 reducer 进行处理达到负载均衡目的。第二次再根据去掉key的随机前缀，按原key进行reduce处理。<br>这个方法进行两次mapreduce，性能稍差</p>
</li>
<li><p>「增加Reducer，提升并行度」<br><code>JobConf.setNumReduceTasks(int)</code></p>
</li>
<li><p>「实现自定义分区」<br>根据数据分布情况，自定义散列函数，将key均匀分配到不同Reducer</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/" data-id="ckxprkvpv0001fksofrj03610" data-title="hadoop面试题" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/" rel="tag">hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag">面试</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/12/23/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E7%BB%8F%EF%BC%882021-11%E6%9C%88%EF%BC%89/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          大数据面经（2021/11月）
        
      </div>
    </a>
  
  
    <a href="/2021/12/20/Java%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0%E9%A2%98/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Java基础练习题</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/" rel="tag">hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/" rel="tag">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E7%BB%83%E4%B9%A0/" rel="tag">java基础语法练习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag">面试</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/docker/" style="font-size: 10px;">docker</a> <a href="/tags/hadoop/" style="font-size: 10px;">hadoop</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%E7%BB%83%E4%B9%A0/" style="font-size: 10px;">java基础语法练习</a> <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" style="font-size: 10px;">大数据</a> <a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 20px;">面试</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">December 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/12/23/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E7%BB%8F%EF%BC%882021-11%E6%9C%88%EF%BC%89/">大数据面经（2021/11月）</a>
          </li>
        
          <li>
            <a href="/2021/12/20/hadoop%E9%9D%A2%E8%AF%95%E9%A2%98/">hadoop面试题</a>
          </li>
        
          <li>
            <a href="/2021/12/20/Java%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0%E9%A2%98/">Java基础练习题</a>
          </li>
        
          <li>
            <a href="/2021/12/20/Centos7%E5%AE%89%E8%A3%85Docker/">Centos7安装Docker</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>